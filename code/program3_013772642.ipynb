{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPE 256 Programming Assignment 3 - Social Network Analysis\n",
    "\n",
    "#### Dataset Used: Wikipidea Vote taken from https://snap.stanford.edu/data/wiki-Vote.html\n",
    "\n",
    "#### About the data:\n",
    "\n",
    "The network contains all the Wikipedia voting data from the inception of Wikipedia till January 2008. Nodes in the network represent wikipedia users and a directed edge from node i to node j represents that user i voted on user j.\n",
    "\n",
    "#### Networkx:\n",
    "NetworkX is a Python package for the creation, manipulation, and study of the structure, dynamics, and functions of complex networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset into networkx using edgelist method and creating a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: \\nType: DiGraph\\nNumber of nodes: 7115\\nNumber of edges: 103689\\nAverage in degree:  14.5733\\nAverage out degree:  14.5733'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import heapq\n",
    "\n",
    "G=nx.read_edgelist(\"../data/Wiki-Vote.txt\", create_using=nx.DiGraph())\n",
    "nx.info(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As given in the dataset description, the graph is directed. Hence, I used the nx.DiGraph() function to intialize the graph as a directed one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Number of Nodes in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of nodes present in the graph is :  7115\n"
     ]
    }
   ],
   "source": [
    "nodes= nx.number_of_nodes(G)\n",
    "print(\"The number of nodes present in the graph is : \" ,nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Number of Edges in the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of edges present in the graph is :  103689\n"
     ]
    }
   ],
   "source": [
    "edges= nx.number_of_edges(G)\n",
    "print(\"The number of edges present in the graph is : \" ,edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Checking if the graph is connected or not and displaying the number of connected components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Checking if the Graph is Connected or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_strongly_connected(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have checked and found that the graph is not strongly connected, let us find the number of connected components in the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Finding the Number of Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of weakly connected componenets in graph is:  24\n",
      "The number of strongly connected componenets in graph is:  5816\n"
     ]
    }
   ],
   "source": [
    "components1= nx.number_weakly_connected_components(G)\n",
    "print(\"The number of weakly connected componenets in graph is: \",components1) \n",
    "\n",
    "components2 = nx.number_strongly_connected_components(G)\n",
    "print(\"The number of strongly connected componenets in graph is: \",components2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_con_comp = nx.strongly_connected_components(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Diameter (longest shortest path) of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As the graph is strongly connected, the diameter will be infinite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Average clustering coefficient of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average clustering coefficient of the graph is:  0.08156344522820935\n"
     ]
    }
   ],
   "source": [
    "avg_clus_coeff = nx.average_clustering(G)\n",
    "print(\"The average clustering coefficient of the graph is: \",avg_clus_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Closeness & Betweenness Centralities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Top 5 nodes with the highest closeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "type(closeness_centrality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closeness_centrality() of networkx returns a dictionary of the nodes and their closeness centrality values. In the next cell, I used the heapq library of python to get the top 5 nodes with the highest closeness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 nodes having highest closeness centrality are:\n",
      "Node: 4037\n",
      "Node: 15\n",
      "Node: 2398\n",
      "Node: 1549\n",
      "Node: 2535\n"
     ]
    }
   ],
   "source": [
    "k = heapq.nlargest(5, closeness_centrality, key=closeness_centrality.get)\n",
    "print(\"The top 5 nodes having highest closeness centrality are:\")\n",
    "for i in k:\n",
    "    print(\"Node:\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Top 5 nodes with the highest betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "type(betweenness_centrality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The betweenness_centrality() of networkx returns a dictionary of the nodes and their betweenness centrality values. In the next cell, I used the heapq library of python to get the top 5 nodes with the highest betweenness centrality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 nodes having highest betweenness centrality are:\n",
      "Node: 2565\n",
      "Node: 1549\n",
      "Node: 15\n",
      "Node: 72\n",
      "Node: 737\n"
     ]
    }
   ],
   "source": [
    "k1 = heapq.nlargest(5, betweenness_centrality, key=betweenness_centrality.get)\n",
    "print(\"The top 5 nodes having highest betweenness centrality are:\")\n",
    "for i in k1:\n",
    "    print(\"Node:\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Dispersion between the two nodes with highest PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagerank = nx.pagerank(G)\n",
    "type(pagerank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pagerank() of networkx returns a dictionary of the nodes and their pagerank values. In the next cell, I used the heapq library of python to get the top 2 nodes with the highest pagerank values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nodes having highest PageRank are:\n",
      "Node: 4037\n",
      "Node: 15\n"
     ]
    }
   ],
   "source": [
    "k2 = heapq.nlargest(2, pagerank, key=pagerank.get)\n",
    "print(\"The nodes having highest PageRank are:\")\n",
    "for i in k2:\n",
    "    print(\"Node:\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dispersion between the two nodes with highest PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dispersion of the two noded can be found by passing them as arguments to the dispersion() function of networkx library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dispersion of the two nodes with the highest pageranks is: 0.0\n"
     ]
    }
   ],
   "source": [
    "dispersion2 = nx.dispersion(G,u=\"4037\",v=\"15\")\n",
    "print(\"The dispersion of the two nodes with the highest pageranks is:\", dispersion2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Top Five nodes with the highest authority score according to HITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hubs, authority_score = nx.hits(G, normalized=False)\n",
    "type(authority_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hits() function of networkx library returns a tuple of hub values and authority scores. The authority scores are in dictionary format, in the next step, by using heapq library, the top 5 nodes with highest authority scores can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5 nodes having highest authority scores according to HITS are:\n",
      "Node: 2398\n",
      "Node: 4037\n",
      "Node: 3352\n",
      "Node: 1549\n",
      "Node: 762\n"
     ]
    }
   ],
   "source": [
    "k3 = heapq.nlargest(5, authority_score, key=authority_score.get)\n",
    "print(\"The top 5 nodes having highest authority scores according to HITS are:\")\n",
    "for i in k3:\n",
    "    print(\"Node:\",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Communities using the Girvan Newman algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For finding the communities in the given graph using Girvan Newman Algorithm, we use the girvan_newman() function. <br>\n",
    "For this step, I converted the directed graph as an undirected one for feasiblity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "G1 = G.to_directed()\n",
    "communities = girvan_newman(G1, most_valuable_edge=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The girvan_newman() function returns a generator format. The generator is an iterator of tuples of sets of nodes in the graph. Each set of node is a community, each tuple is a sequence of communities at a particular level of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_comm = tuple(sorted(c) for c in next(communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using Girvan Newman algorithm, the number of communities in the given graph are:  25\n"
     ]
    }
   ],
   "source": [
    "print(\"By using Girvan Newman algorithm, the number of communities in the given graph are: \",len(sorted_comm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Top 5 nodes for each community found using Girvan Newman algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 nodes in each community: \n",
      "['10', '100', '1000', '1001', '1002']\n",
      "['6687', '6688', '6689', '6690', '6691']\n",
      "['2304', '2305']\n",
      "['3194', '3195']\n",
      "['3244', '3245']\n",
      "['4167', '4168']\n",
      "['4540', '4541']\n",
      "['5413', '5414']\n",
      "['5678', '5679']\n",
      "['5766', '5767']\n",
      "['5970', '5971']\n",
      "['6002', '6025']\n",
      "['6089', '6090']\n",
      "['6100', '6101']\n",
      "['6258', '6259']\n",
      "['6266', '6267']\n",
      "['7031', '7032', '7033']\n",
      "['7190', '7191']\n",
      "['7194', '7195']\n",
      "['7465', '7466', '7467']\n",
      "['7494', '7495']\n",
      "['7972', '7973']\n",
      "['7981', '7982']\n",
      "['8014', '8015']\n",
      "['8074', '8075', '8076']\n"
     ]
    }
   ],
   "source": [
    "print(\"The 5 nodes in each community: \")\n",
    "for i in range(0,len(sorted_comm)):\n",
    "    print(sorted_comm[i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each community has different number of nodes, the minimum community being 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussions:\n",
    "\n",
    "- The dataset contains only 2 columns, FromNodeId and ToNodeId\n",
    "- Networkx is used to build the graph and load the edges from the dataset\n",
    "- The in built functions of networkx such as closeness_centrality(), betweenness_centrality(), diameter(), pagerank(), hits() are used for the analysis of the graph.\n",
    "- Girvan Newman algorithm is used to find the communities in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "- https://networkx.github.io/documentation/stable/index.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
